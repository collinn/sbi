---
output: html_document
---

# Study Design {#ch3}

> "Randomization is too important to be left to chance."  
>
> --- J. D. Petruccelli

<div class="objective-container">
<div class="objectives"> Learning objectives </div>
1. Be familiar with the general principles of study design
2. Understand how poor study design can bias results
3. Learn about various sampling biases, such as selection and non-response bias
4. Be familiar with other types of bias, such as extrapolation and confounding
5. Know what a randomized controlled double-blind experiment is and why it is the gold standard
</div>

## Importance of Study Design {#ch3_s1}

In Chapter 1, we defined statistics by its ability to quanitfy uncertainty regarding the potential outcome of a random process. In order to do this most effectively and make accurate inference, researchers and statisticians do their best to remove potential sources of variability. Variability can manifest in a number of ways, ranging from the standard biological variability associated with a given population (genetic variation), as well as imprecision associated with measurement (measuring blood pressure, weight, etc.,). While these sources of variation do impact the ability to make precise inference, the effects associated with this kind of variability often "even out" in the end.

Similar to variability is the concept of **bias**. Whereas variability is used to describe the effects of random variation and imprecision, bias refers to a characteristics of a process or technique in which the measured outcome is *systematically different* from the true value it is meant to represent. For example, a researcher may be interested in taking the weight of patients at different times during the day. Due to fluctuations in metabolism, an individual patient may have a slightly different weight at different times of the day, resulting in variability. However, if the scale that is used is miscalibrated and always reports a weight that is ten pounds less than the true value, this would be bias. Unfortunately, there are very few tools at a statisticians disposal to address bias, and there is frequently no way to test if it is present or not. However, a well designed study can reduce this risk and put researchers and statisticians in the best possible place to perform successful science. 

As a critical piece of the statistical framework, **study design** is the process of organizing, conducting, and analyzing a scientific experiment with the intention of resolving a hypothesis or achieving research goals. There are many types of study designs with various strengths and limitaitons, the entirety of which could not possibly be covered here. Instead, we will focus on some of the main considerations when designing a study, as well as the statistical implications associated with common ways in which study design can go wrong.


```{tikz statFramework3, fig.cap = "Statistical Framework", fig.ext = 'png', echo = F, fig.align = 'center'}
\usetikzlibrary{decorations.pathreplacing,positioning, arrows, shapes, calc,shapes.multipart}
\tikzstyle{block1} = [rectangle, draw, fill=yellow!20, 
    text width=10em, text centered, rounded corners, minimum height=6em]
\tikzstyle{block2} = [rectangle, draw, fill=yellow!20, 
    text width=5em, text centered, rounded corners, minimum height=3em]
\tikzset{
    %Define standard arrow tip
    >=stealth,
    % Define arrow style
    pil/.style={
           ->,
           thick,
           shorten <=2pt,
           shorten >=2pt,}
}
\tikzstyle{line} = [draw, -latex]
\begin{tikzpicture}[node distance = 3cm, auto]
            % Place nodes
            \node [block1] (pop) {Population};
            \node [block2, below of=pop] (samp) {Sample};
            
            % Draw edges
            \draw[->, >=latex, shorten >=2pt, shorten <=2pt, bend right=45, thick]  (pop.west) to node[auto, swap] {Study Design}(samp.west);
            \draw[->, >=latex, shorten >=2pt, shorten <=2pt, bend right=45, thick] (samp.east) to node[auto, swap] {Inference}(pop.east); 
            
        \end{tikzpicture}
```

In an ideal world, the study design process might look a little bit like this: 

1. We start with a list of everyone in our population of interest. 
2. Each person in this population is equally easy to sample, and the cost of sampling everyone is the same
3. We use our list to randomly select a proportion of individuals in the population who will participate in our study
4. Everybody sampled is eager to help us with our study, and nobody refuses to participate
5. The outcome of interest can be accurately measured on each subject and directly answers the research question.

Of course, real life situations are rarely ideal.

Bias can occur at various points during a research study and materialize
in many forms. The ability to identify bias is a crucial skill for researchers
to have when evaluating the merit of other studies in the literature or designing studies of their own. In this chapter, we focus on defining several
common types of bias common in medical research, how each type can impact study results, and how they can
be avoided. This is not meant to be an exhaustive list -- if you are interested in
learning about other types of bias, check out the [Catalogue of Biases](https://catalogofbias.org/biases/).
We will categorize different types 
of bias broadly by when they occur: pre-trial, during trial, and 
post-trial, although all types of bias should be considered when planning 
a study.


<div class="definition-container">
<div class="definition"> &nbsp; </div>
**Scientific/Research Bias: ** <em> Any process or technique whereby the actual outcome is
  systematically different from the true value it is intended to estimate </em>
  
**Study design: ** <em> The process of obtaining the best sample to answer the research questions </em>
</div>

## Pre-trial Bias {#ch3_s2}

Pre-trial biases describe a collection of biases that can be introduced into a study before it even begins. Generally, these are associated with ensuring that our sample is representative of the population in question and that the study is designed in such a way that meaningful comparisons can be made.

### Selection Bias {#ch3_s2_ss1}

<!-- The first major consideration when planning a study involves collecting a *random sample* that is *representative* of the population of interest, a process that is covered in greater detail in [Chapter 7](#ch7). When our sample is collected in such a way that the members of our sample are *systematically different* from the population, we are at risk of **selection bias**. For example, suppose we are interested in knowing how the citizens of Iowa City feel about a proposal that would raise property taxes, but would give free ice cream daily to  -->

The first major consideration when planning a study is who you will ask
to participate. When selecting your sample, you must ensure the sample is 
representative of the population of interest. Otherwise, your study may be prone to
**selection bias**, where the study participants differ systematically from the
population of interest. For example, in the first phase of a vaccine 
trial, the vaccine is often given to young, healthy volunteers to assess its safety 
profile. However, the vaccine is intended for use for both young and older people,
as well as those that may have underlying medical conditions. If the safety  of
the vaccine was only determined based on the initial studies in healthy 
participants, it would look safer than it really is. This is why these initial 
studies are primarily used to stop development of a vaccine that is unsafe.
Vaccines that are found to be safe in healthy people proceed to further 
testing in the general population to accurately determine the safety profile. 
Selection bias can be avoided by careful consideration of the make up of the 
population and a sampling method that accounts for various sub-populations that
may differ in respect to the study outcome.

### Non-response/Participant Bias {#ch3_s3_ss2}

We remarked earlier that in an ideal world, all selected participants would be 
eager to participate in our study. However, this is not always the case. To make
matters even more difficult, sometimes those that want to participate in our 
study differ in meaningful ways from those that do participate. This is called  
**non-response or participant bias**. This type of bias can occur in many studies,
but is often a particular concern for studies that send out surveys or election 
polls. For example, consider the end-of-semester teaching evaluations that provide
students an opportunity to review their instructor anonymously. When students 
are not required to fill out these evaluations, its likely that only students 
with strong opinions about their instructor will take the time to respond. This
may cause the final evaluations to be a mix of very negative ratings and very 
positive ratings, whereas the instructor's actual performance maybe be somewhere in the 
middle. Participant bias can be avoided when designing a study by reducing the 
survey length and offering incentives for participation. 


### Confirmation Bias/Placebo Effect {#ch3_s2_ss3}

I hate this.

To determine if a new treatment is effective, it must be compared to something 
else. This is addressed by splitting the sample into two groups: the 
**treatment group** and the **control group**. Subjects in the treatment group
are given the vaccine, whereas subjects in the control group are not treated 
and are used for comparison. Subjects must be assigned to receive the treatment
or control at random to avoid selection bias. In addition, there is the potential
for bias to arise if the subjects know whether or not they're being treated. This
is known as **confirmation bias**, where the knowledge of treatment allocation 
can make study participants perceive the treatment benefit differently. To 
avoid this and ensure that any differences in the outcome are due to the treatment,
researchers use a **placebo**, or fake treatment (e.g. a sugar pill
or saline infection). 


through what is called the **placebo effect**. The placebo effect

Blinding is used to address or control for the placebo effect.




<div class="definition-container">
<div class="definition"> &nbsp; </div>
**Selection Bias: ** <em> A type of bias in which subgroups of the population were more likely to be included than others </em>

**Non-response/participant Bias: ** <em> A type of bias in which non-participants differ in a 
  meaningful way from the participants</em>

**Treatment group: ** <em> The part of the sample that receives the treatment </em>

**Control Group: ** <em> The part of the sample that is not treated for comparison purposes </em>
  
**Confirmation Bias: ** <em> Bias due to an individuals prior beliefs</em>

**Placebo Effect: ** <em> A psychological phenomenon where an inactive treatment can produce a positive response </em>
  
</div>


## During-trial Bias {#ch3_s3}



### Confounding {#ch3_s3_ss1}

Many epidemiological studies have shown that coffee drinkers have an increased 
risk of lung cancer. However, upon further investigation, researchers also 
noticed that smokers are more likely to drink coffee. There is a known association
between smoking and lung cancer, with people who smoke cigarettes being 15 to 
30 times more likely to develop lung cancer than people who do not. Thus the
association that was detected between coffee and lung cancer was not due to the 
coffee, and instead was impacted by smoking status. 

```{tikz coffeeCancer, fig.cap = "Coffee causes cancer?", fig.ext = 'png', echo = F, fig.align = 'center'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning}
\tikzset{
    -Latex,auto,node distance =1 cm and 1 cm,semithick,
    state/.style ={ellipse, draw, minimum width = 0.7 cm},
    point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
    bidirected/.style={Latex-Latex,dashed},
    el/.style = {inner sep=2pt, align=left, sloped}
}
\begin{tikzpicture}
                \node[state] (1) at (0,0) {Coffee Drinker};
                \node[state] (3) at (6, 0) {Lung Cancer};
                \node[state] (4) at (3, 1.5) {Smoker};
            
                \path (1) edge  (3);
                \path (4) edge (3);
                \path (4) edge (1);
            \end{tikzpicture}
```

Once researchers *controlled* for smoking status, they no longer found a change
in lung cancer risk due to [drinking coffee](https://cebp.aacrjournals.org/content/25/6/951).
Smoking status is said to be a *confounder*, also known as a *lurking variable*.
A confounder is a third variable related to both exposure and outcome. Because 
of this relationship, confounders distort the observed relationship between 
exposure and outcome.

Confounding can be avoided when designing the study by ensuring the treatment 
and control groups have similar distributions of each confounding variable. In 
the coffee and cancer example, this would be analogous to ensuring there were
similar proportions of smokers in the coffee drinking and non-coffee drinking 
groups. If it is not possible to control for a confounder when designing the 
study, there are many analysis methods (beyond the scope of this course) that
can be used.



### Observer Bias {#ch3_s3_ss2}

Researchers often have expectations about how effective their treatment is 
(otherwise they probably wouldn't be studying it). If the researcher is also 
responsible for recording subjective assessments of the study participants, there
is the potential for their beliefs about the treatment to influence either how they perceive


<div class="definition-container">
<div class="definition"> &nbsp; </div>
**Confounding: ** <em>  </em>
  
**Observer Bias: ** <em> Bias arising when observers record subjective data </em>

</div>



## Post-trial Bias {#ch3_s4}

> "To consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of."  
>
> --- R. A. Fisher

Once a study has been completed, there is often very little that can be done to correct potential biases made during or before the study began. That being said, researchers still have a responsibility to present their findings in ways that can promote future research.


### Compliance Bias {#ch3_s4_ss1}

Despite individuals being willing to participate in a research study, this does
not always mean they will comply perfectly with their assigned treatment. 
Consider an exercise study designed to help people lose weight. Individuals that 
are heavier and out of shape may tend to skip some of the workouts or drop out
of the study at a higher rate than individuals that are in better shape prior
to starting the study. Since compliance is directly tied to the outcome of interest
(weight loss), bias may occur causing the exercise plan to look less effective
than it truly is. Bias due to compliant participants differing from non-compliant
participants is called **compliance bias**. Consider a 1980 study of the drug
clofibrate, which is designed to reduce blood cholesterol levels to prevent 
coronary heart disease. Participants were randomly assigned to take up to three 
capsules of either clofibrate or placebo three times per day. At follow-up 
visits, the remaining number of capsules were counted to estimate how many each
participant actually took each day. When comparing those that adhered (took at 
least 80% of their required capsules) to those that did not the study results were:

```{r, echo = F}
library(knitr)
library(kableExtra)
tmp <- data.frame('Count' = c('708', '357', '1,103'),
                  'Deaths' = c('15%', '25%', '20%'))

rownames(tmp) <- c('Adherers', 'Non-adherers', 'Total')
kbl(tmp, align = 'c', col.names = c('# of Clofibrate Patients', 'Deaths')) |> 
  kable_styling(full_width = FALSE)
```

When comparing adherers and non-adherers in the clofibrate group, we see that
non-adherers were much more likely to die. This seems to provide strong evidence
that clofibrate is effective, however we have ignored the results of the patients
in the placebo group.

```{r, echo = F}
tmp2 <- data.frame('Count' = c('1,813', '882', '2,789'),
                  'Deaths' = c('15%', '28%', '21%'))

rownames(tmp2) <- c('Adherers', 'Non-adherers', 'Total')

kbl(cbind.data.frame(tmp, tmp2),
      align = 'c', col.names = c('# of Clofibrate Patients', 'Deaths', 
                                   '# of Placebo Patients', 'Deaths')) |> 
  kable_styling(full_width = FALSE)
#|> 
 # kable_paper("hover", full_width = FALSE) |> kable_styling(position = "float_right")
```

When comparing patients in the clofibrate group to those that were on the placebo,
we see the same trend of reduced mortality in adherers. Additionally, the death
rate for adherers taking clofibrate is exactly the same as that for patients
taking the placebo. This would indicate that clofibrate is not the reason for
reduced mortality; instead, it is driven by characteristics of those that 
adhere to their medication. One possibility is that adherers are more concerned
with their health in general, and are thus more likely to take better care of 
themselves. Compliance bias can be avoided by comparing subjects only by the
groups to which they were randomized, despite their adherence to the treatment. This 
is also called **intent-to-treat (ITT) analysis**.


### Extrapolation Bias {#ch3_s4_ss2}

The previous two examples demonstrated ways in which we might incorrectly move 
from a target population to a non-representative sample. This final case 
describes movement in the opposite direction: from a specified sample to a more 
general population. Nonetheless, the cause of the bias is the same.

The motivation here can be most readily illustrated by considering the issue of 
pharmaceutical trails and the use of children. For practical, ethical, and
economic reasons, clinical trials usually only involve adults - indeed, only 
about 25% of drugs are subjected to pediatric studies. Physicians, however, are 
allowed to use any FDA-approved drug in any way that they think is beneficial 
are are not required to inform parents if the therapy has not been tested on 
children. 


### Publication Bias {#ch3_s4_ss3}



<div class="definition-container">
<div class="definition"> &nbsp; </div>
**Compliance Bias: ** <em> Bias arising when those complying to study protocol differ from
  those that do not comply</em>  
  
**Intent-to-treat (ITT) analysis: ** <em> A method of analysis which includes all participants
  as they were randomized despite adherence</em>  

**Extrapolation Bias: ** <em>  </em>

**Publication Bias: ** <em> A bias in published research which favors significant findings </em>

</div>

