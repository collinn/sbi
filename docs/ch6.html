<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Sampling Distributions and the Central Limit Theorem | Seriously Interesting Statistics Textbook</title>
  <meta name="description" content="First template!" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Sampling Distributions and the Central Limit Theorem | Seriously Interesting Statistics Textbook" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="First template!" />
  <meta name="github-repo" content="ceward/introTextbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Sampling Distributions and the Central Limit Theorem | Seriously Interesting Statistics Textbook" />
  
  <meta name="twitter:description" content="First template!" />
  

<meta name="author" content="Caitlin Ward and Collin Nolte" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch5.html"/>
<link rel="next" href="ch7.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="ch4.html"><a href="ch4.html"><i class="fa fa-check"></i><b>1</b> Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch4.html"><a href="ch4.html#ch4_s1"><i class="fa fa-check"></i><b>1.1</b> Understanding Randomness</a></li>
<li class="chapter" data-level="1.2" data-path="ch4.html"><a href="ch4.html#ch4_s2"><i class="fa fa-check"></i><b>1.2</b> Probability Operations</a></li>
<li class="chapter" data-level="1.3" data-path="ch4.html"><a href="ch4.html#ch4_s3"><i class="fa fa-check"></i><b>1.3</b> Conditional Probability</a></li>
<li class="chapter" data-level="1.4" data-path="ch4.html"><a href="ch4.html#ch4_s4"><i class="fa fa-check"></i><b>1.4</b> Probabilities from tables (needs a different example)</a></li>
<li class="chapter" data-level="1.5" data-path="ch4.html"><a href="ch4.html#ch4_s5"><i class="fa fa-check"></i><b>1.5</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch5.html"><a href="ch5.html"><i class="fa fa-check"></i><b>2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch5.html"><a href="ch5.html#ch5_s1"><i class="fa fa-check"></i><b>2.1</b> Introduction to Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch5.html"><a href="ch5.html#a-final-note"><i class="fa fa-check"></i><b>2.1.1</b> A final note</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch5.html"><a href="ch5.html#ch5_s2"><i class="fa fa-check"></i><b>2.2</b> Binomial Distribution</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch5.html"><a href="ch5.html#plot-of-binomial"><i class="fa fa-check"></i><b>2.2.1</b> Plot of Binomial</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch5.html"><a href="ch5.html#ch5_s3"><i class="fa fa-check"></i><b>2.3</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ch5.html"><a href="ch5.html#plot-for-normal"><i class="fa fa-check"></i><b>2.3.1</b> Plot for Normal</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch5.html"><a href="ch5.html#poisson-distribution"><i class="fa fa-check"></i><b>2.4</b> Poisson Distribution</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ch5.html"><a href="ch5.html#plots-for-poisson"><i class="fa fa-check"></i><b>2.4.1</b> Plots for Poisson</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch5.html"><a href="ch5.html#t-distribution"><i class="fa fa-check"></i><b>2.5</b> t Distribution</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ch5.html"><a href="ch5.html#plot-for-t-distribution"><i class="fa fa-check"></i><b>2.5.1</b> Plot for t distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch5.html"><a href="ch5.html#review-of-distributions"><i class="fa fa-check"></i><b>2.6</b> Review of Distributions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch6.html"><a href="ch6.html"><i class="fa fa-check"></i><b>3</b> Sampling Distributions and the <br/> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="3.1" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="ch6.html"><a href="ch6.html#sampling-distributions"><i class="fa fa-check"></i><b>3.2</b> Sampling Distributions</a></li>
<li class="chapter" data-level="3.3" data-path="ch6.html"><a href="ch6.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch7.html"><a href="ch7.html"><i class="fa fa-check"></i><b>4</b> Introduction to Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch7.html"><a href="ch7.html#ch7_s1"><i class="fa fa-check"></i><b>4.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="4.2" data-path="ch7.html"><a href="ch7.html#ch7_s2"><i class="fa fa-check"></i><b>4.2</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="4.3" data-path="ch7.html"><a href="ch7.html#ch7_s3"><i class="fa fa-check"></i><b>4.3</b> P-values</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch13.html"><a href="ch13.html"><i class="fa fa-check"></i><b>5</b> Introduction to Simulations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch13.html"><a href="ch13.html#ch13_s1"><i class="fa fa-check"></i><b>5.1</b> What is a simulation?</a></li>
<li class="chapter" data-level="5.2" data-path="ch13.html"><a href="ch13.html#why-simulation"><i class="fa fa-check"></i><b>5.2</b> Why Simulation</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ch13.html"><a href="ch13.html#non-simulation-methods"><i class="fa fa-check"></i><b>5.2.1</b> Non-simulation Methods</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch13.html"><a href="ch13.html#simulation-method"><i class="fa fa-check"></i><b>5.2.2</b> Simulation Method</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch13.html"><a href="ch13.html#chapter-summary"><i class="fa fa-check"></i><b>5.3</b> Chapter Summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Seriously Interesting Statistics Textbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch6" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Sampling Distributions and the <br/> Central Limit Theorem</h1>
<blockquote>
<p>“While nothing is more uncertain than a single life, nothing is more certain than the average duration of a thousand lives.” - Elizur Wright</p>
</blockquote>
<blockquote>
<p>“Everything that can be counted does not necessarily count; everything that counts cannot necessarily be counted.” - Albert Einstein</p>
</blockquote>
<div class="objective-container">
<div class="objectives">
Learning objectives
</div>
<ol style="list-style-type: decimal">
<li>Learn to differentiate between statistics and parameters<br />
</li>
<li>Understand the concept of sampling distributions<br />
</li>
<li>Conceptual understanding of Central Limit Theorem and how it applies to sample means</li>
</ol>
</div>
<div id="introduction" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>Suppose policy makers and public health experts in Iowa are concerned with Iowan’s fast food intake. To understand this further, the officials want to determine the average monthly spending on fast food for all Iowans. However, it would be very expensive and costly to have all 3.2 million Iowans track and report their total monthly spending on fast food. And certainly many Iowans would not be willing to share personal financial details with public health researchers or government officials. This means it is impossible for the officials to know the true mean amount of money that Iowans spend on fast food each month. The true numeric quantity about the population, such as this, is known as a <strong>population parameter</strong>. While we will never ever know the truth, there are still options. The officials can take a sample of Iowans and have those that consent to share their information report their monthly spending on fast food. Then, they can take the sample mean, which gives them an estimate of the average monthly spending on fast food. The sample mean is an example of a <strong>sample statistic</strong>, which is a numerical quantity about the sample. In other words, statistics are what investigators know, and parameters are what investigators want to know. The statistical framework (pictured below) allows us to make <strong>inference</strong> about population parameters using sample statistics. This means the researchers can use a random sample of Iowans’ monthly fast food spending to make generalizations about the average monthly spending for all Iowans. The numerical quantities of interest can be many different things - means, proportions, standard deviations, etc.. In the fast food example, the parameter of interest was a population mean and the sample statistic was the sample mean. In this chapter, we will specifically focusing on estimating means.</p>
<div class="figure"><span id="fig:statFramework"></span>
<img src="introTextbookTemplate_files/figure-html/statFramework-1.png" alt="Statistical Framework" width="672" />
<p class="caption">
Figure 3.1: Statistical Framework
</p>
</div>
<p>The statistical framework outlines the process of making inference using sample statistics to estimate population parameters. Later chapters in this textbook will cover the mathematical details of this process. In trying to make proper inference, we also want to ensure our estimated statistic is measuring the parameter well. To that end, there are two major statistical issues we concern ourselves with:</p>
<ul>
<li>On average, does our estimate tend to be centered around the true answer, or is it <em>biased</em>?<br />
</li>
<li>How much <em>variability</em> is there likely to be in our sample?</li>
</ul>
<p>The difference between our estimate and our parameter is called <strong>bias</strong>. <strong>Variance</strong> describes the spread of our data, and is sometimes called noise. Sometimes we talk about spread in terms of <strong>precision</strong>, which is the inverse of variance. The more precision we have, the less variance, and vice versa. A good statistic will have little or no bias and would have minimal variability. We can visualize both bias and variability using a dart board analogy.</p>
<div class="figure" style="text-align: center"><span id="fig:image-ref-for-in-text2"></span>
<img src="images/biasVariabilityTargets2.png" alt="Bias and Variability Illustration" width="1000" />
<p class="caption">
Figure 3.2: Bias and Variability Illustration
</p>
</div>
<p>On the upper left target, the darts are hitting the bullseye with low bias and low variability, shown by the darts having minimal spread and all hitting the bullseye. This is the most desirable outcome when the goal is to hit the bullseye. In the upper right target, we see a lot more variability, as the darts are no longer highly concentrated on the bullseye. However, the dart locations are still centered around the bullseye, and this is why we consider this target to have low bias. This situation is less ideal than having low bias and low variance, but is stil preferable to targets in the bottom row, where we have high bias. In the bottom left target, we have high bias and low variability, evidence by the high concentration of darts that are not hitting the bullseye. The consistency is why we saw there is low variability, but if our goal is to hit the bullseye, we are not going to acheive that goal. Finally, the bottom right target is the worst possible outcome - high bias <em>and</em> high variability. We are not hitting the bullseye and the darts are landing erratically. Statisticians work hard to develop inferential procedures that allow us to estimate population parameters with little to no bias and low variability.</p>
<div class="definition-container">
<div class="definition">
Definitions
</div>
<p><strong>Population Parameter: </strong> <em> The true numeric quantity about a population </em></p>
<p><strong>Sample Statistic: </strong> <em> A numerical quantity about the sample </em></p>
<p><strong>Inference: </strong> <em> The process of making generalizations about the population </em></p>
<p><strong>Bias: </strong> <em> The difference between our estimate and our parameter </em></p>
<p><strong>Variability: </strong> <em> The spread or error in the data </em></p>
<p><strong>Precision: </strong> <em> Inverse of variance, how </em></p>
</div>
</div>
<div id="sampling-distributions" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Sampling Distributions</h2>
<p>In order to make inference, we must be able to quantify our uncertainty about the population parameter based on our sample data. To quantify our uncertainty, we must first establilsh where it comes from - the sampling process. Any time we take a sample from the population, we will get a different sample mean <span class="math inline">\(\bar{x}\)</span>. In other words, <span class="math inline">\(\bar{x}\)</span> is a numeric quantity which assumes a value based on the outcome of a random experiment - the process of drawing a sample at random from the population. This should sound familiar - this is the definition of a random variable! We can use this logic for any statistic of interest. As we’ve described in the past, random variables have probability distributions. When the random variable is a statistic, this probability distribution is called the sampling distribution. Sampling distributions reflect which values of the statistic are likely and which values are improbable. As we will see later in this chapter, this uncertainty depends on how many individuals we sample and how variable the data we measure is.</p>
<p>A VISUALIZATION ABOUT SAMPLING DISTRIBUTIONS WOULD BE COOL HERE. SOMETHING THAT SHOWS ALL THE UNITS IN THE POPULATION WITH NUMERIC VALUES ON THEM, THEN TAKE SAMPLE AND CALCULATE MEAN.</p>
<p>I think what would be neat is doing dot plots for a population and have them be all one color, say, red. Once the samples are chosen, they will be presented below with their own distribution in blue. BUT! The ones selected in the random sample would also turn blue, indicating that they were picked. Maybe this is like what that shiny app you showed me was?</p>
<p>As we’ve seen earlier in this book, we will use upper-case letters to denote random variables, and lower-case letters to denote possible values they can take on. When it comes to the sampling distribution of the mean, <span class="math inline">\(\bar{X}\)</span> is the random variable, which arises from repeated random sampling from the population and then taking a sample mean, and <span class="math inline">\(\bar{x}\)</span> is an observed sample mean we might see. In describing a sampling distribution, we are often interested in the mean and standard deviation - this gives information about typical values the statistic might take on as well as how spread out the distribution is. We refer to the mean of a statistic as the <strong>expected value</strong> and the standard deviation as the <strong>standard error</strong>. For the random variable describing the sample mean, these are denoted as <span class="math inline">\(E(\bar{X})\)</span> and <span class="math inline">\(SE(\bar{X}) = \sqrt{Var(\bar{X})}\)</span>, respectively.</p>
<p>Another good way to address the <span class="math inline">\(\bar{X}\)</span> vs <span class="math inline">\(\bar{x}\)</span> is to have something like (&amp;= isn’t making them align?)</p>
<div class="latex">
<p><span class="math display">\[
\begin{align*}
\bar{X} &amp;= \{\text{Mean height of} \textit{ Sex and the City } \text{protagonists}\} \\
\bar{x} &amp;= \{\text{Mean height of Carrie and Samantha}\}
\end{align*}
\]</span></p>
</div>
<div class="definition-container">
<div class="definition">
Definitions
</div>
<p><strong>Expected Value: </strong> <em> The mean of a statistic in repeated sampling </em></p>
<p><strong>Standard Error: </strong> <em> The standard deviation of a statistic in repeated sampling </em></p>
</div>
</div>
<div id="central-limit-theorem" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Central Limit Theorem</h2>
<p>Example</p>
<p>We will use the fast food scenario to motivate our sample, but for let’s assume there are only five individuals in the entire population. The monthly spending for those five individuals (rounded to the nearest dollar) is as follows:</p>
<table>
<thead>
<tr class="header">
<th align="left">Person</th>
<th align="left">Monthly Spending</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left">22</td>
</tr>
<tr class="odd">
<td align="left">C</td>
<td align="left">22</td>
</tr>
<tr class="even">
<td align="left">D</td>
<td align="left">36</td>
</tr>
<tr class="odd">
<td align="left">E</td>
<td align="left">50</td>
</tr>
</tbody>
</table>
<p>The population mean can be found by taking the average monthly spending of these five individuals, as they are the only people in this population. This means the population mean is 27.6. Now suppose we are taking samples of three individuals from this population. There are <span class="math inline">\(\binom{5}{3}\)</span> = 10 ways we can sample three people from this population. Since this is a small population, we can enumerate all possible samples, the values we would obtain for the monthly spending in each sample, and then the sample mean monthly fast food spending for each sample:</p>
<table style="width:100%;">
<colgroup>
<col width="39%" />
<col width="48%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Sample</th>
<th align="left">Values</th>
<th align="right"><span class="math inline">\(\bar{x}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(A, B, C)</td>
<td align="left">(8, 22, 22)</td>
<td align="right">17.33</td>
</tr>
<tr class="even">
<td align="left">(A, B, D), (A, C, D)</td>
<td align="left">(8, 22, 36), (8, 22, 36)</td>
<td align="right">22.00</td>
</tr>
<tr class="odd">
<td align="left">(A, B, E), (A, C, E), (B, C, D)</td>
<td align="left">(8, 22, 50), (8, 22, 50), (22, 22, 36)</td>
<td align="right">22.00</td>
</tr>
<tr class="even">
<td align="left">(A, D, E), (B, C, E)</td>
<td align="left">(8, 36, 50), (22, 22, 50)</td>
<td align="right">26.67</td>
</tr>
<tr class="odd">
<td align="left">(B, D, E), (C, D, E)</td>
<td align="left">(22, 36, 50), (22, 36, 50)</td>
<td align="right">36.00</td>
</tr>
</tbody>
</table>
<p>One thing to note is that <em>none</em> of the sample means are actually equal to the population mean. This is often the case! Based on this table, we can construct the sampling distribution of <span class="math inline">\(\bar{X}\)</span> for a sample of size three.</p>
<div class="infobox think">
<p>Why is our sample mean often not equal to the population mean?</p>
</div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">P(<span class="math inline">\(\bar{x}\)</span> = 17.33)</td>
<td align="left">0.1</td>
</tr>
<tr class="even">
<td align="left">P(<span class="math inline">\(\bar{x}\)</span> = 22)</td>
<td align="left">0.2</td>
</tr>
<tr class="odd">
<td align="left">P(<span class="math inline">\(\bar{x}\)</span> = 26.67)</td>
<td align="left">0.3</td>
</tr>
<tr class="even">
<td align="left">P(<span class="math inline">\(\bar{x}\)</span> = 31.33)</td>
<td align="left">0.2</td>
</tr>
<tr class="odd">
<td align="left">P(<span class="math inline">\(\bar{x}\)</span> = 36)</td>
<td align="left">0.2</td>
</tr>
</tbody>
</table>
<p>With this probability distribution, we can get the expected value of the sampling distribution. Whenever we think about probability, we are thinking about long-run frequencies, so when we think about the expected value, we are thinking about the average sample mean if we were to take repeated samples of size three from this population. The probability distribution indicates that if we took samples of size three from this population over and over again (say 1,000 times), we would end up with 10% with a mean of 17.33, 20% with a mean of 22, 30% with a mean of 26.67; and so on. So the expected value (average) we would observed if we kept taking samples over and over would be:</p>
<p>(0.1 <span class="math inline">\(\times\)</span> 17.33) + (0.2 <span class="math inline">\(\times\)</span> 22) + (0.3 <span class="math inline">\(\times\)</span> 26.67) + (0.2 <span class="math inline">\(\times\)</span> 31.33) + (0.2 <span class="math inline">\(\times\)</span> 36) = 27.6</p>
<p>But wait! That is the population mean. This illustrates an extremely powerful property of the sample mean - the expected value of the sample mean (<span class="math inline">\(\bar{X}\)</span>) is equal to the population parameter (<span class="math inline">\(\mu\)</span>)! Because of this, we say that the sample mean is an <strong>unbiased estimator</strong> of the population mean. While we illustrated the property with a small example, this holds regardless of the population or sample size.</p>
<p>
<p>Important Formula!</p>
<p>For <em>any</em> population distribution which can be described by a random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, the sample distribution of the mean based on sample of size <span class="math inline">\(n\)</span> (<span class="math inline">\(\bar{X}_n\)</span>) has the following properties:</p>
<ol style="list-style-type: decimal">
<li>The expected value of the sampling distribution is <span class="math inline">\(\mu\)</span>
<span class="math display">\[E(\bar{X}_n) = \mu\]</span></li>
<li>The variance of the sampling distribution is
<span class="math display">\[Var(\bar{X}_n) = \frac{\sigma^2}{n}\]</span></li>
</ol>
</p>
<p>Using these formulas we are able to describe the typical value of the sample mean and how variable the sample mean is in repeated sampling. Notice that the expected value does not depend on the sample size, <span class="math inline">\(n\)</span>, but the variance does. This means regardless of the sample size, the sample mean is an unbiased estimator of the population mean. But, as the sample size increases, the variance decreases, and we get a more precise estimate of the population mean. As we’ve seen in the past, it is more common to talk about the standard deviation than the variance and the standard deviation is the square root of the variance. The quantity <span class="math inline">\(\sqrt{Var(\bar{X}_n)} = \sigma / n\)</span> is primarily called the <strong>standard error</strong> of the mean, and is denoted by <span class="math inline">\(SE(\bar{X}_n)\)</span>. We use the term standard error to make it really clear that it is referencing the sampling distribution of the mean, but all standard errors could be refered to as standard deviations. Conversely, not all standard deviations could be referred to as a standard error - the term is only used in describing the distribution of the sample mean.</p>
<p>
<p>Example
Let <span class="math inline">\(X\)</span> denote the resting heart rate of a randomly selected U.S. adult. Assume the distribution of resting heart rates is approximately normally distributed with mean 70 bpm and standard deviation of 5 bpm. Suppose we sample 50 adults. Let <span class="math inline">\(\bar{X}\)</span> denote the mean resting heart rate of these 50 adults.</p>
<ol style="list-style-type: decimal">
<li><p>What is the mean of <span class="math inline">\(\bar{X}\)</span>? (That is, in repeated sampling, what would be the average value of <span class="math inline">\(\bar{X}\)</span>?)</p></li>
<li><p>What is the standard error of <span class="math inline">\(\bar{X}\)</span></p></li>
</ol>
</p>
<div class="exercise">
Exercises
</div>
<!-- frameBorder="0" -->
<iframe src="https://ph-shiny.iowa.uiowa.edu/ceward/textbook/CLT" width="100%" height="800">
</iframe>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
