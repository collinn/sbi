<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Sampling Distributions and the Central Limit Theorem | An Intuitive, Interactive, Introduction to Biostatistics</title>
  <meta name="description" content="6 Sampling Distributions and the Central Limit Theorem | An Intuitive, Interactive, Introduction to Biostatistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Sampling Distributions and the Central Limit Theorem | An Intuitive, Interactive, Introduction to Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="ceward/introTextbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Sampling Distributions and the Central Limit Theorem | An Intuitive, Interactive, Introduction to Biostatistics" />
  
  
  

<meta name="author" content="Caitlin Ward and Collin Nolte" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch6.html"/>
<link rel="next" href="ch8.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch1.html"><a href="ch1.html#ch1_s1"><i class="fa fa-check"></i><b>1.1</b> Statistics and Evidence-based Research</a></li>
<li class="chapter" data-level="1.2" data-path="ch1.html"><a href="ch1.html#ch1_s2"><i class="fa fa-check"></i><b>1.2</b> Scientific Method</a></li>
<li class="chapter" data-level="1.3" data-path="ch1.html"><a href="ch1.html#ch1_s3"><i class="fa fa-check"></i><b>1.3</b> Statistical framework</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2.html"><a href="ch2.html"><i class="fa fa-check"></i><b>2</b> Data Summaries and Presentation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2.html"><a href="ch2.html#ch2_s1"><i class="fa fa-check"></i><b>2.1</b> Introduction to Data</a></li>
<li class="chapter" data-level="2.2" data-path="ch2.html"><a href="ch2.html#ch2_s2"><i class="fa fa-check"></i><b>2.2</b> Categorical Data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch2.html"><a href="ch2.html#ch2_s2_ss1"><i class="fa fa-check"></i><b>2.2.1</b> Basic Categorical Summaries</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch2.html"><a href="ch2.html#ch2_s2_ss2"><i class="fa fa-check"></i><b>2.2.2</b> Advanced Categorical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch2.html"><a href="ch2.html#ch2_s3"><i class="fa fa-check"></i><b>2.3</b> Continuous Data</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ch2.html"><a href="ch2.html#ch3_centrality"><i class="fa fa-check"></i><b>2.3.1</b> Measures of Centrality</a></li>
<li class="chapter" data-level="2.3.2" data-path="ch2.html"><a href="ch2.html#ch3_dispersion"><i class="fa fa-check"></i><b>2.3.2</b> Measures of Dispersion</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch2.html"><a href="ch2.html#ch2_s4"><i class="fa fa-check"></i><b>2.4</b> Advanced Data Visualizations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch3.html"><a href="ch3.html"><i class="fa fa-check"></i><b>3</b> Study Design</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch3.html"><a href="ch3.html#ch3_s1"><i class="fa fa-check"></i><b>3.1</b> Importance of Study Design</a></li>
<li class="chapter" data-level="3.2" data-path="ch3.html"><a href="ch3.html#ch3_s22"><i class="fa fa-check"></i><b>3.2</b> Variability and Bias</a></li>
<li class="chapter" data-level="3.3" data-path="ch3.html"><a href="ch3.html#clinical-trials"><i class="fa fa-check"></i><b>3.3</b> Clinical Trials</a>
<ul>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#study-protocol-and-human-subjects"><i class="fa fa-check"></i>Study Protocol and Human Subjects</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#participant-selection"><i class="fa fa-check"></i>Participant Selection</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#control-groups-and-randomization"><i class="fa fa-check"></i>Control Groups and Randomization</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#blinding"><i class="fa fa-check"></i>Blinding</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#compliance-and-intent-to-treat-itt"><i class="fa fa-check"></i>Compliance and Intent-To-Treat (ITT)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch3.html"><a href="ch3.html#biases"><i class="fa fa-check"></i><b>3.4</b> Biases</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch3.html"><a href="ch3.html#ch3_s2"><i class="fa fa-check"></i><b>3.4.1</b> Pre-trial Bias</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch3.html"><a href="ch3.html#ch3_s3"><i class="fa fa-check"></i><b>3.4.2</b> During-trial Bias</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch3.html"><a href="ch3.html#ch3_s4"><i class="fa fa-check"></i><b>3.4.3</b> Post-trial Bias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch4.html"><a href="ch4.html"><i class="fa fa-check"></i><b>4</b> Introduction to Probability and Simulation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch4.html"><a href="ch4.html#ch4_s1"><i class="fa fa-check"></i><b>4.1</b> Randomness and Simulation</a></li>
<li class="chapter" data-level="4.2" data-path="ch4.html"><a href="ch4.html#ch4_s2"><i class="fa fa-check"></i><b>4.2</b> Probability</a></li>
<li class="chapter" data-level="4.3" data-path="ch4.html"><a href="ch4.html#ch4_s3"><i class="fa fa-check"></i><b>4.3</b> Methods for Computing Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch6.html"><a href="ch6.html"><i class="fa fa-check"></i><b>5</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch6.html"><a href="ch6.html#introduction-to-probability-distributions"><i class="fa fa-check"></i><b>5.1</b> Introduction to Probability Distributions</a></li>
<li class="chapter" data-level="5.2" data-path="ch6.html"><a href="ch6.html#binomial-distribution"><i class="fa fa-check"></i><b>5.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="ch6.html"><a href="ch6.html#normal-distribution"><i class="fa fa-check"></i><b>5.3</b> Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch7.html"><a href="ch7.html"><i class="fa fa-check"></i><b>6</b> Sampling Distributions and the <br/> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch7.html"><a href="ch7.html#introduction-to-sampling"><i class="fa fa-check"></i><b>6.1</b> Introduction to Sampling</a></li>
<li class="chapter" data-level="6.2" data-path="ch7.html"><a href="ch7.html#sampling-distributions"><i class="fa fa-check"></i><b>6.2</b> Sampling Distributions</a></li>
<li class="chapter" data-level="6.3" data-path="ch7.html"><a href="ch7.html#central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch8.html"><a href="ch8.html"><i class="fa fa-check"></i><b>7</b> Introduction to Inference</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch8.html"><a href="ch8.html#ch8_s1"><i class="fa fa-check"></i><b>7.1</b> Statistical Inference</a></li>
<li class="chapter" data-level="7.2" data-path="ch8.html"><a href="ch8.html#ch8_s2"><i class="fa fa-check"></i><b>7.2</b> Point Estimation and Confidence Intervals</a></li>
<li class="chapter" data-level="7.3" data-path="ch8.html"><a href="ch8.html#ch8_s3"><i class="fa fa-check"></i><b>7.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="7.4" data-path="ch8.html"><a href="ch8.html#ch8_s4"><i class="fa fa-check"></i><b>7.4</b> P-values</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Intuitive, Interactive, Introduction to Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch7" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Sampling Distributions and the <br/> Central Limit Theorem</h1>
<blockquote>
<p>“While nothing is more uncertain than a single life, nothing is more certain than the average duration of a thousand lives.” - Elizur Wright</p>
</blockquote>
<blockquote>
<p>“Everything that can be counted does not necessarily count; everything that counts cannot necessarily be counted.” - Albert Einstein</p>
</blockquote>
<div class="objective-container">
<div class="objectives">
Learning objectives
</div>
<ol style="list-style-type: decimal">
<li>Learn to differentiate between statistics and parameters<br />
</li>
<li>Understand the concept of sampling distributions<br />
</li>
<li>Conceptual understanding of Central Limit Theorem and how it applies to sample means</li>
</ol>
</div>
<div id="introduction-to-sampling" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Introduction to Sampling</h2>
<p>Suppose policy makers and public health experts in Iowa are concerned with Iowans’ fast food intake. To understand this further, officials want to determine the average monthly spending on fast food for all Iowans. It would be very expensive, however, to have all 3.2 million Iowans track and report their total monthly fast food expenses. Whats more, many Iowans would not be willing to share personal financial details with public health researchers or government officials. These are but a few of the challenges making it practically impossible for officials to ever determine the true average spent by Iowans each month on fast food.</p>
<p>A true numeric quantity about the population, here assumed to be the mean, is known as a <strong>population parameter</strong>. While we may never know the exact value of a population parameter, we have tools at our disposal to estimate it. For example, officials can determine a <em>representative sample</em> of Iowans and have those consenting to share their information report their monthly fast food spending. The average spending of this group is the <em>sample mean</em>, which can then be used approximate the population mean. The sample mean is an example of a <strong>sample statistic</strong>, which is a numerical quantity about the sample. In other words, statistics are what investigators know, and parameters are what investigators want to know.</p>
<p>The statistical framework (pictured below) demonstrates the process of making <strong>inference</strong> about population parameters with the use of sample statistics, as was done in the example above. The numerical quantities of interest can be many different things - means, proportions, standard deviations, etc.,. While the methods of estimation are similar in each case, the present chapter will focus specifically on estimations of the mean. (maybe mention here that this is general discussion with mathematical derivations saved for a later chapter)</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:statFramework2"></span>
<img src="introTextbookTemplate_files/figure-html/statFramework2-1.png" alt="Statistical Framework" width="672" />
<p class="caption">
Figure 6.1: Statistical Framework
</p>
</div>
<p>The statistical framework outlines the general process of making inference using sample statistics to estimate population parameters. In trying to make proper inference, we want to ensure our that our calculated statistic is a valid estimate of the population parameter of interest. To that end, there are two major statistical issues we concern ourselves with:</p>
<ul>
<li>On average, does our estimate tend to be centered around the true answer, or is it <em>biased</em>?<br />
</li>
<li>How much <em>variability</em> is there likely to be in our sample?</li>
</ul>
<p>The difference between our estimate and our parameter is called <strong>bias</strong>. <strong>Variance</strong> (or “noise”) is a description of the spread of our data. Sometimes we talk about spread in terms of <strong>precision</strong>, which is the reciprocal of variance. The more precision we have, the less variance, and vice-versa. A good statistic will have little or no bias and would have minimal variability. We can visualize both bias and variability using a dart board analogy:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:image-ref-for-in-text2"></span>
<img src="images/biasVariabilityTargets2.png" alt="Bias and Variability Illustration" width="1000" />
<p class="caption">
Figure 6.2: Bias and Variability Illustration
</p>
</div>
<p>In terms of priority, having a low bias is generally more desirable than low variance, and this is represented in the top row above. Having low bias indicates that our sample statistic is correctly estimating the population parameter of interest, even if our statistic is considered “noisy.” Variance, illustrated in the columns, gives an idea of how “consistent” our estimate is. One way to think of it is to consider the throwing of a dart to the collection of a sample; comparing the top right and bottom left corners, we might say it is better throw generally close to the target than to consistently miss it entirely. Statisticians work hard to develop sampling and inferential procedures that allow us to estimate population parameters with little low variability and little to no bias.</p>
<hr />
<div class="definition-container">
<div class="definition">
<span id="def:unlabeled-div-28" class="definition"><strong>Definition 6.1  </strong></span> 
</div>
<div class="text">
<p><strong>Population Parameter: </strong> <em> The true numeric quantity describing a population (i.e., the population mean) </em></p>
<p><strong>Sample Statistic: </strong> <em> A numerical quantity about the sample, often used to estimate a population parameter </em></p>
<p><strong>Inference: </strong> <em> The process of making generalizations about the population based on sampling statistics </em></p>
<p><strong>Bias: </strong> <em> The systematic difference between our estimate and our parameter </em></p>
<p><strong>Variability: </strong> <em> The spread or noise in the data </em></p>
<p><strong>Precision: </strong> <em> Inverse of variance, how narrow the data is </em></p>
</div>
</div>
</div>
<div id="sampling-distributions" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Sampling Distributions</h2>
<p>In order to make inference, we must be able to quantify our uncertainty about the population parameter based on our sample data. To illustrate this uncertainty, consider again our example above in estimating the average expenditures of Iowans on fast food, and suppose that researchers decide to sample 500 individuals from the population and calculate the sample mean, <span class="math inline">\(\overline{x}\)</span>. Now suppose that those same researchers go out and collect a <em>second</em> sample of 500 individuals from the population and calculate the sample mean again, which me might call <span class="math inline">\(\overline{x}_2\)</span>. Should we expect <span class="math inline">\(\overline{x}\)</span> and <span class="math inline">\(\overline{x}_2\)</span> to be exactly the same? What if they did this again and calculated <span class="math inline">\(\overline{x}_3\)</span>? Or <span class="math inline">\(\overline{x}_4\)</span>?</p>
<p>As we might expect, it is very unlikely that any of these will be exactly equal to any of the others, though they might be close. But if none of these sample means are equal to each other, how accurate might we expect any of them to be with regards to estimating our population parameter? Herein lies the question of quantifying our uncertainty. Fortunately, statisticians have created powerful methods for being able to do so accurately, even when only a single sample statistic has been obtained.</p>
<p>We might first begin by recognizing that the process of sampling from a population is itself a <em>random experiment</em>, with the sample mean <span class="math inline">\(\overline{x}\)</span> being a numeric quantity which assumes a value based on the outcome of that experiment. This should sound familiar – this is precisely the definition of a random variable! Just as with other random variables, sample statistics themselves also follow a probability distribution. When the random variable itself is a statistic, we call the probability distribution a <strong>sampling distribution</strong>. Sampling distributions reflect which values of the statistic are likely if we were to repeat the sampling process (that is, likely values for <span class="math inline">\(\overline{x}_2\)</span>, <span class="math inline">\(\overline{x}_3\)</span>, etc.,), and which values are improbable. We might then expect that the value of the true population parameter will fall somewhere within the range of likely values. [[As we will see later in this chapter, this uncertainty depends on the number of individuals sampled and the variability of the data we measure.]]</p>
<div class="exercise-container">
<div class="exercise">
<span id="exr:unlabeled-div-29" class="exercise"><strong>Exercise 6.1  </strong></span> 
</div>
<div class="text">
<p>The applet below is designed to help you get familiar with the concept of random sampling. The plot on the left side gives a population distribution consisting of 25 people, where each subject in the population is represented by one box. The x-axis represents the value of the outcome variable for each individual, with stacked boxes indicating that multiple people have the same value. For example, we have one subject in the population with a value of zero, three subjects with values of one, and so on.</p>
<p>The plot on the right displays values for the subjects collected in our random sample, with the same subjects being highlighted in green on the left. We can take samples from our population of various sizes by changing the value of the slider at the top and clicking on the “Sample” button.</p>
</div>
</div>
<!-- frameBorder="0" -->
<iframe src="https://ph-ivshiny.iowa.uiowa.edu/ceward/textbook/shinyApps/sampling/" width="100%" height="800">
</iframe>
<div class="exercise-container">
<ol>
<li>
Set the sample size to 2 and click the “Sample” button five times. Fill out the following table with the sample means observed in your five samples.
<table style="width:50%">
<tr>
<th style="text-align:center">
Sample Number
</th>
<th>
Sample mean
</th>
</tr>
<tr>
<td style="text-align:center">
1
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
2
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
3
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
4
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
5
</td>
<td>
</td>
</tr>
</table>
<ol style="list-style-type: lower-alpha;">
<li>
Did you get the same sample mean for any of your five samples?
</li>
<li>
Was the sample mean ever equal to the population mean in any of your five samples? If not, how close were your sample means to the true population mean?
</li>
</ol>
</li>
<li>
Now set the sample size to 15 and click the “Sample” button five times. Fill out the following table with the sample means observed in your five samples.
<table style="width:50%">
<tr>
<th style="text-align:center">
Sample Number
</th>
<th>
Sample mean
</th>
</tr>
<tr>
<td style="text-align:center">
1
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
2
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
3
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
4
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:center">
5
</td>
<td>
</td>
</tr>
</table>
<ol style="list-style-type: lower-alpha;">
<li>
Did any of your five simulations give you a sample mean equal to the population mean?
</li>
<li>
How close were your sample means to the true population mean?
</li>
</ol>
</li>
<li>
Compare your results from problems 1 and 2.
<ol style="list-style-type: lower-alpha;">
<li>
In either case were you able to obtain a sample mean equal to the population mean?
</li>
<li>
Which one had sample means with more variability? What does this indicate about the relationship between the sample size and the distribution of sample means in the context of repeated sampling?
</li>
</ol>
</li>
</ol>
</div>
<p>Following the conventions used previously, we will use upper-case letters to denote random variables and lower-case letters to denote values that have been observed (that is, they are no longer random). Regarding the sampling distribution of the mean, <span class="math inline">\(\overline{X}\)</span> represents the random variable which arises from the repeated random sampling from the population, while <span class="math inline">\(\overline{x}\)</span> represents an <em>observed</em> sample mean from an already collected sample.</p>
<p>In describing the sampling distribution, we are often interested in the mean and the standard deviation which, together, describe the size of the interval of probable values for our population parameter. When describing statistics with a sampling distribution, we refer to the sample mean as the <strong>expected value</strong> of our statistic, while the standard deviation is referred to as the <strong>standard error</strong>. For the random variable describing the sample mean, these are denoted as <span class="math inline">\(E(\overline{X})\)</span> and <span class="math inline">\(SE(\overline{X}) = \sqrt{Var(\overline{X})}\)</span>, respectively.</p>
<p>Let’s return to the fast food scenario to motivate our development, but for now let’s assume there are only five individuals in the entire population. The monthly spending for those five individuals (rounded to the nearest dollar) is as follows:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Person
</th>
<th style="text-align:left;">
Monthly Spending
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:left;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:left;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:left;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:left;">
36
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:left;">
50
</td>
</tr>
</tbody>
</table>
<p>The population mean can be found by taking the average monthly spending of these five individuals, as they are the only people in this population. This means the population mean is 27.6. Now suppose we are taking samples of three individuals from this population. There are <span class="math inline">\(\binom{5}{3}\)</span> = 10 ways we can sample three people from this population. Since this is a small population, we can enumerate all possible samples, the values we would obtain for the monthly spending in each sample, and then the sample mean monthly fast food spending for each sample:</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Sample
</th>
<th style="text-align:left;">
Values
</th>
<th style="text-align:right;">
<span class="math inline">\(\overline{x}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(A, B, C)
</td>
<td style="text-align:left;">
(8, 22, 22)
</td>
<td style="text-align:right;">
17.33
</td>
</tr>
<tr>
<td style="text-align:left;">
(A, B, D), (A, C, D)
</td>
<td style="text-align:left;">
(8, 22, 36), (8, 22, 36)
</td>
<td style="text-align:right;">
22.00
</td>
</tr>
<tr>
<td style="text-align:left;">
(A, B, E), (A, C, E), (B, C, D)
</td>
<td style="text-align:left;">
(8, 22, 50), (8, 22, 50), (22, 22, 36)
</td>
<td style="text-align:right;">
22.00
</td>
</tr>
<tr>
<td style="text-align:left;">
(A, D, E), (B, C, E)
</td>
<td style="text-align:left;">
(8, 36, 50), (22, 22, 50)
</td>
<td style="text-align:right;">
26.67
</td>
</tr>
<tr>
<td style="text-align:left;">
(B, D, E), (C, D, E)
</td>
<td style="text-align:left;">
(22, 36, 50), (22, 36, 50)
</td>
<td style="text-align:right;">
36.00
</td>
</tr>
</tbody>
</table>
<p>One thing to note is that <em>none</em> of the sample means are actually equal to the population mean. This is often the case! Based on this table, we can construct the sampling distribution of <span class="math inline">\(\overline{X}\)</span> for a sample of size three.</p>
<div class="infobox think">
<p>Why is our sample mean often not equal to the population mean?</p>
</div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
P(<span class="math inline">\(\overline{x}\)</span> = 17.33)
</td>
<td style="text-align:left;">
0.1
</td>
</tr>
<tr>
<td style="text-align:left;">
P(<span class="math inline">\(\overline{x}\)</span> = 22)
</td>
<td style="text-align:left;">
0.2
</td>
</tr>
<tr>
<td style="text-align:left;">
P(<span class="math inline">\(\overline{x}\)</span> = 26.67)
</td>
<td style="text-align:left;">
0.3
</td>
</tr>
<tr>
<td style="text-align:left;">
P(<span class="math inline">\(\overline{x}\)</span> = 31.33)
</td>
<td style="text-align:left;">
0.2
</td>
</tr>
<tr>
<td style="text-align:left;">
P(<span class="math inline">\(\overline{x}\)</span> = 36)
</td>
<td style="text-align:left;">
0.2
</td>
</tr>
</tbody>
</table>
<p>With this probability distribution, we can get the expected value of the sampling distribution. Whenever we think about probability, we are thinking about long-run frequencies, so when we think about the expected value, we are thinking about the average sample mean if we were to take repeated samples of size three from this population. The probability distribution indicates that if we took samples of size three from this population over and over again (say 1,000 times), we would end up with 10% with a mean of 17.33, 20% with a mean of 22, 30% with a mean of 26.67; and so on. So the expected value (average) we would observed if we kept taking samples over and over would be:</p>
<p>(0.1 <span class="math inline">\(\times\)</span> 17.33) + (0.2 <span class="math inline">\(\times\)</span> 22) + (0.3 <span class="math inline">\(\times\)</span> 26.67) + (0.2 <span class="math inline">\(\times\)</span> 31.33) + (0.2 <span class="math inline">\(\times\)</span> 36) = 27.6</p>
<p>But wait! That <em>is</em> the population mean. This illustrates an extremely powerful property of the sample mean - the expected value of the sample mean <span class="math inline">\(\overline{X}\)</span> is equal to the population parameter <span class="math inline">\(\mu\)</span>! Because of this, we say that the sample mean is an <strong>unbiased estimator</strong> of the population mean. While we illustrated the property with a small example, this holds regardless of the population or sample size.</p>
<hr />
<div class="definition-container">
<div class="definition">
<span id="def:unlabeled-div-30" class="definition"><strong>Definition 6.2  </strong></span> 
</div>
<div class="text">
<p><strong>Sampling Distribution: </strong> <em> A probability distribution associated with a sample statistic </em></p>
<p><strong>Expected Value: </strong> <em> The mean value of a statistic in repeated sampling </em></p>
<p><strong>Standard Error: </strong> <em> The standard deviation of a statistic (including the mean) in repeated sampling </em></p>
<p><strong>Unbiased Estimator: </strong> <em> The statistic with an expected value equal to the true population parameter</em></p>
</div>
</div>
</div>
<div id="central-limit-theorem" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Central Limit Theorem</h2>
<p>In the last section, we used a toy example to conceptualize repeated sampling and the property of the sample mean being an unbiased estimator. Now we will formalize these properties. For <em>any</em> population distribution which can be described by a random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, the sample distribution of the mean based on sample of size <span class="math inline">\(n\)</span>, denoted <span class="math inline">\(\overline{X}_n\)</span>, has the following properties:</p>
<ol style="list-style-type: decimal">
<li>The expected value of the sampling distribution is <span class="math inline">\(\mu\)</span>
<span class="math display">\[E(\overline{X}_n) = \mu\]</span></li>
<li>The variance of the sampling distribution is
<span class="math display">\[Var(\overline{X}_n) = \frac{\sigma^2}{n}\]</span></li>
</ol>
<p>Together, these expressions are used to describe the typical value of the sample mean as well as the expected amount of variability in the sample mean under repeated sampling. From this, there are two further observations that are worth noting:</p>
<ol style="list-style-type: decimal">
<li><p>The expected value of the sample mean is always equal to <span class="math inline">\(\mu\)</span>, regardless of the size of the sample: this property makes the sample mean an <em>unbiased</em> estimator of the population mean.</p></li>
<li><p>Whereas the expected value of the sample mean does not depend on <span class="math inline">\(n\)</span>, the variance of the sampling distribution does. Indeed, this should match our intuition; as the size of our sample increases, the variability of <span class="math inline">\(\overline{X}_n\)</span> decreases, giving us a more precise estimate of the population mean.</p></li>
</ol>
<p>As we’ve seen already, it is more common to discuss the standard deviation of a
statistic than the variance. In the context of sampling distributions, this quantity
is called the <em>standard error</em> (to emphasize that we are discussing a sampling
distribution) and is denoted</p>
<p><span class="math display">\[SE(\overline{X}_n) = \sqrt{Var(\overline{X}_n)} = \sigma / \sqrt{n}\]</span></p>
<p>Note that while all standard errors could be referred to as standard deviations,
the converse does not hold – standard deviations not associated with a sampling
distribution are never referred to as standard errors.</p>
<!-- Using these formulas we are able to describe the typical value of the sample mean and how variable the sample mean is in repeated sampling. Notice that the expected value does not depend on the sample size, $n$, but the variance does. This means regardless of the sample size, the sample mean is an unbiased estimator of the population mean. But, as the sample size increases, the variance decreases, and we get a more precise estimate of the population mean. As we've seen in the past, it is more common to talk about the standard deviation than the variance and the standard deviation is the square root of the variance. The quantity $\sqrt{Var(\overline{X}_n)} = \sigma / \sqrt{n}$ is primarily called the **standard error** of the mean, and is denoted by $SE(\overline{X}_n)$. We use the term standard error to make it really clear that it is referencing the sampling distribution of the mean, but all standard errors could be referred to as standard deviations. Conversely, not all standard deviations could be referred to as a standard error - the term is only used in describing the distribution of the sample mean. -->
<p>Until now, we have discussed the mean and standard error of a random statistic
without having described the sampling <em>distribution</em> itself. Why might having
the distribution of a statistic be useful? Recall from the previous chapter that
we defined a distribution as a method of associating an event or outcome with
its corresponding probability. As we shall see, the sample mean, along with
its standard error, will help us in constructing a range of “likely” values
that may contain the true parameter. With the use of a sampling distribution,
we will now be able to assign a probability to the range of these likely values.</p>
<p>As it turns out, the process of randomly collecting a sample from a population
and computing its sample means has a truly amazing property – the sampling
distribution will always be normally distributed. This brings us to what is
largely considered the “fundamental theorem of statistics.”</p>
<p><strong>Central Limit Theorem</strong></p>
<p>What the Central Limit Theorem (CLT) states is this: so long as the size of our sample is “large enough,” the sampling distribution of <span class="math inline">\(\overline{X}\)</span> will be approximately normal, regardless of the characteristics of the underlying distribution. That is, we have</p>
<p><span class="math display">\[\overline{X}_n \sim N(\mu, \sigma^2/n).\]</span></p>
<p>While the term “large enough” will inevitably depend on the context of the problem at hand, a typical rule of thumb puts this value at <span class="math inline">\(n \geq 30\)</span>. Because the variance of <span class="math inline">\(\overline{X}\)</span> is inversely related to the sample size, as the <span class="math inline">\(n\)</span> increases, the variance decreases and the distribution becomes more concentrated around its mean value. This is one of the most important, remarkable, and powerful results in all of statistics. In the real world, we rarely know the underlying population distribution of our data, yet the CLT assures us that this is not an issue. In the next chapter, we will investigate how the consequences of the CLT create an immensely powerful tool in performing statistical inference.</p>
<div class="exercise-container">
<div class="exercise">
<span id="exr:unlabeled-div-31" class="exercise"><strong>Exercise 6.2  </strong></span> 
</div>
<div class="text">
<p>The applet below is designed to help your conceptual understanding of the CLT. You can change the underlying population distribution, the size of the samples taken (<span class="math inline">\(n\)</span>), and the number of experiments performed. Each experiment consists of taking a sample of the specified size from the population and calculating the sample mean. The top left panel (blue) shows the underlying population distribution. The top right panel (red) shows the data from the most recent sample, with the sample mean from that specific sample indicated by the dashed black line. The bottom panel (gold) shows us the distribution of sample means from all the experiments, with the observed mean of the sample means indicated by the dashed black line and the true underlying population mean indicated by the solid blue line. Once you select the parameters to the values you want, click “Run Simulation” to tabulate the results.</p>
</div>
</div>
<!-- frameBorder="0" -->
<iframe src="https://ph-ivshiny.iowa.uiowa.edu/ceward/textbook/shinyApps/CLT/" width="100%" height="800">
</iframe>
<div class="exercise-container">
<ol>
<li>
Set the population distribution to Normal, the sample size to 30 and perform 100 experiments to collect 100 sample means.
<ol style="list-style-type: lower-alpha;">
<li>
Describe the histogram of the the data from the last experiment. Comment on the modality and skew.
</li>
<li>
Describe the histogram of the distribution of sample means from all experiments.
</li>
<li>
What is the range of values observed for the distribution of sample means? How does this compare the the range of values observed in the data from the last experiment?
</li>
</ol>
</li>
<li>
Now adjust the sample size to 100. Perform 100 experiments.
<ol style="list-style-type: lower-alpha;">
<li>
What is the range of values observed for the distribution of sample means? How does this compare to the range observed when the sample size was 30?
</li>
<li>
What about the range of values observed in the data from the last experiment – did this change much when the sample size was increased?
</li>
<li>
Play around with various sample sizes. How does changing the sample size effect the spread of the distribution of sample means?
</li>
</ol>
</li>
<li>
Return to a sample size of 30, but change the population distribution to be right skewed. Perform 1,000 experiments.
<ol style="list-style-type: lower-alpha;">
<li>
Describe the histogram of the the data from the last experiment. Comment on the modality and skew.
</li>
<li>
Describe the histogram of the distribution of sample means from all experiments. Does it resemble the population distribution?
</li>
<li>
Re-run the simulation using a sample size of 10. How does this effect the distribution of the sample means? How does this compare to what you observed when taking samples of size 10 with a normal population distribution?
</li>
</ol>
</li>
<li>
Change the population distribution to be left skewed, set the sample size to 80, and perform 1,000 experiments.
<ol style="list-style-type: lower-alpha; ">
<li>
Describe the histogram of the the data from the last experiment. Comment on the modality and skew.
</li>
<li>
Describe the histogram of the distribution of sample means from all experiments. Does it resemble the population distribution?
</li>
<li>
Run the simulation with these parameters a few times and pay attention to how the mean of the distribution of sample means compares to the population mean. Is the population mean similar or different from the mean of the sample means? What property does this illustrate?
</li>
</ol>
</li>
<li>
Change the parameters of the simulations as needed to answer the following true/false questions. Explain your answers.
<ol style="list-style-type: lower-alpha; ">
<li>
CLT tells us that the distribution of data from any experiment will be normally distributed.
</li>
<li>
With a larger sample size, the data from the last experiment will resemble the population distribution.
</li>
<li>
Performing 10 experiments is enough to see the effect of CLT.
</li>
<li>
Regardless of the underlying population distribution and the sample size, the distribution of the sample means will be normally distributed.
</li>
<li>
Increasing the sample size causes the data from a single experiment to look more and more normally distributed.
</li>
</ol>
</li>
</ol>
</div>
<hr />
<div class="definition-container">
<div class="definition">
<span id="def:unlabeled-div-32" class="definition"><strong>Definition 6.3  </strong></span> 
</div>
<div class="text">
<p><strong>Central Limit Theorem: </strong> <em> A mathematical theorem that provides us with the sampling
distribution of the mean </em></p>
</div>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch6.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch8.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
