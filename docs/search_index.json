[
["index.html", "Seriously Interesting Statistics Textbook Introduction", " Seriously Interesting Statistics Textbook Caitlin Ward and Collin Nolte Introduction Welcome! This resource offers an interactive learning experience for introductory biostatistics. This resource was designed with the course BIOS:4120 Introduction to Biostatistics at the Unviersity of Iowa in mind, but could be used in any introductory statistics or biostatistics course. We combine textual explanations and embedded simulation-based Shiny applications, to provide students with an engaging learning resource that offers an intuitive illustration of core statistical concepts. The applications and associated exercises are targeted at conceptional understanding, as opposed to calculations. At this point in time, we provide chapters on: Probability (text only) Probability distributions (text and application) Sampling distributions and Central Limit Theorem (text and application) Confidence intervals (text and application) This resource is in a Beta phase "],
["acknowledgements.html", "1 Acknowledgements", " 1 Acknowledgements We would like to acknowledge the funding which made the creation of this resource possible, provided a the University of Iowa Libraries OpenHawks grant. "],
["ch5.html", "2 Probability Distributions 2.1 Introduction to Probability Distributions 2.2 Binomial Distribution 2.3 Normal Distribution 2.4 Poisson Distribution 2.5 t Distribution 2.6 Review of Distributions", " 2 Probability Distributions Learning objectives Understand the definition of a probability distribution Binomial distribution Normal distribution t distribution In the previous chapter, we introduced the idea of a random processes, situations with outcomes that we could not determine perfectly in advance. The idea of a random process can apply to most everything in our lives, from the exact amount of time it takes to go from home to class, to determining the winner of a football game. Further, recall that a random process is defined by the collection of possible events and their associated probabilities, [framed in terms of long run frequencies (discuss?)]. In the coin flipping example, where the coin was flipped three times, the collection of possible events was \\[\\mathcal{S} = \\{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT\\},\\] and the associated probabilities for the number of heads were: ## Why does this need cbind? knitr::kable(cbind.data.frame(&#39;# Heads&#39; = 0:3, &#39;Probability&#39; = c(&#39;1/8&#39;, &#39;3/8&#39;, &#39;3/8&#39;, &#39;1/8&#39;)), align = &#39;c&#39;) # Heads Probability 0 1/8 1 3/8 2 3/8 3 1/8 After tabulating all of the possible events, we were able to determine probabilities by tabulating the number of ways each event could occur and dividing by the total number of possibilities (in this case, eight). Of course, this can quickly become cumbersome in general: if three flips resulted in eight possible events, and four flips would result in sixteen, imagine trying to determine all of the possible outcomes of flipping a coin fifty times! Clearly, we need a more efficient way to do this. [I wrote this when it was two. Not sure if we should keep or not, or reword] Further, suppose we were asked to anticipate the number of heads that would occur after three flips. The table above would lead us to conclude that our best guess would be two or three, as it has twice the probability of either of the other outcomes. In other words, the distribution of outcomes is not completely random: there appear to be some structure in the ways these outcomes unfold. This, along with the need for a more precise way of determining possible outcomes and probabilities, leads us to the topic of the current chapter. 2.1 Introduction to Probability Distributions Put simply, a probability distribution is a function that takes a possible event as input, and gives us the resulting probability as output. -In the last chapter, we discussed random processes, events, and probability. We noted that probability is framed in terms of long-run frequencies, or the fraction of time an event occurs if a random processes is repeated over and over. One example we looked at was flipping a coin three times and we were able to determine probabilities for specific events by tabulating the number of ways the event could occur and dividing by the number of possible outcomes of flipping the coin three times. This is a feasible approach when there are not very many possible outcomes, but otherwise can be quite cumbersome. Imagine trying to tabulate all the possible outcomes of flipping a coin 50 times! Yeah, we don&#39;t want to imagine that either. This is where the genius of probability distributions comes to our rescue. A **probability distribution** is a function that describes the probability of all possible outcomes for an experiment. The input to the function is the outcome of interest, and the output is the probability of observing that outcome. Probability distributions typically have one or two **parameters**, which describe the distribution. In the coin flipping example, the parameter would be the number of flips. -Before we get to some of the most commonly used probability distributions and the pre-defined functions, we will illustrate the concept by deriving a probability distribution for our toy example. Before we get to some of the most commonly used distributions, let’s illustrate the concept by formally deriving a probability distribution for our example above. Suppose the experiment consists of flipping a coin three times and recording the number of heads. We will let \\(X\\) denote the number of heads that appear. We know that the possible values \\(X\\) can take on are \\(\\{0, 1, 2, 3\\}\\), since we can’t see more heads than we have flips, and we can’t have less than zero. As we saw in the previous chapter, there are eight possible outcomes and the sample space for this experiment is \\[\\mathcal{S} = \\{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT\\}.\\] For each of these possible outcomes, we can count the number of heads - \\(\\{3, 2, 2, 2, 1, 1, 1, 0\\}\\). To find the probability distribution, we calculate the probability that \\(X\\) takes on each possible value library(knitr) tmpTab &lt;- cbind.data.frame(x = 0:3, &#39;P(X=x)&#39; = c(&#39;1/8&#39;, &#39;3/8&#39;, &#39;3/8&#39;, &#39;1/8&#39;)) kable(tmpTab, align = &#39;c&#39;) x P(X=x) 0 1/8 1 3/8 2 3/8 3 1/8 Since there is one possible event where 0 heads were obtained out of the eight possible events, \\(P(X = 0) = 1/8\\). Similarly, there are three possible events where 1 head was obtained, so \\(P(X = 1) = 3/8\\). If we were to plot this probability distribution, it would look like this x &lt;- 0:3 y &lt;- dbinom(x, 3, 0.5) barplot(y, names.arg = x, xlab = &#39;Number of Heads Observed on Three Flips&#39;, ylab = &#39;Probability&#39;) We can also think about these probabilities from a simulation perspective. In this case, we are repeating the experiment of flipping the coin 3 times over and over. So to examine these probabilities from a simulation, we must simulate flipping three coins repeatedly, each time recording the total number of heads observed out of the three flips. If we do enough simulations, we should see the proportion of times each number of heads occurs follows the probability distribution we just calculated. flipCoin3 &lt;- function() { dat &lt;- rbinom(3, 1, 0.5) sum(dat) } nSims &lt;- 1000 simRes &lt;- replicate(nSims, flipCoin3()) prop.table(table(simRes)) ## simRes ## 0 1 2 3 ## 0.114 0.408 0.351 0.127 2.1.1 A final note There are three more characteristics of probability distributions that will be relevant to us going forward. The first of these is a concept known as independent and identically distributed, often written IID for short. Observations from a random experiment are independent when the value of one observation does not have an impact on the other. For example, if we flip a fair coin twice, the value of the first flip has absolutely no effect on the second. That is, if my first flip results in Heads, the second flip is equally likely to be Heads as it is Tails. A common fallacy related to this is the Gambler’s fallacy, in which an individual, having witnessed a fair coin flip land on Heads 20 times in a row falsely believes there is a higher probability of landing on heads for the 21st flip. In actuality, the probability of landing on heads continues to be 50%. Observations from a random experiment are identically distributed if each observation comes from the same probability function. 10 flips from a fair coin would be identically distributed, while 9 flips from a fair coin and one flip from an unfair coin would not. Next, most of the probability distributions that we will be working with are defined in terms of parameters. Often, distribution functions are defined in the most general way possible, specifying a general structure to a class of problems, using parameters to adjust the distribution to the problem at hand. For instance, all random experiments involving the flipping of coins have a similar structure; what changes betweeen experiments may include the number of times a coin is flipped or the probability of landing on heads. With the use of parameters, a single distribution function can be used to describe a wide variety of possible situations. The last thing we need to know about probability distributions is that there are two types, discrete and continuous. This is a little different than the types of data discussed in Chapter 2 (categorical or continuous). Discrete distributions calculate probabilities for specific numeric values (most often counts). The coin flipping example we just looked at was a discrete distribution, because there were four distinct possibilities of the number of heads we could observe. On the other hand, continuous distributions describe probabilities over a continuum with a smooth curve, such as an individual’s height, weight, or systolic blood pressure. In these distributions, it makes less sense to ask the probability of achieving an exact value (i.e., probability of weighing exactly 153.489 lbs) and more sense to inquire about a range of values (probability that an individual weighs more than 185 lbs). For continuous distributions, probabilities are described by the area under the curve. This is a fourth thing, but maybe we put it closer to a definition of random variable vs observed, though currently that’s defined in a few places. We will let \\(X\\) describe a random variable that follows some distribution, with \\(x\\) being the value of \\(X\\) once it is observed. 2.2 Binomial Distribution The first distribution we will cover is one that we are already familiar with. The binomial distribution is a discrete distribution that describes the number of successes in a fixed number of independent trials in which exactly two outcomes are possible. The term “success” can be confusing depending on the situation; in our previous examples, we have considered “successes” to be the number of heads observed, when we just as well could have been counting the number of tails. Even more confusing, in biomedical trials a “success” could be used to describe an adverse reaction to a drug, or even death. To avoid this confusion, we will instead consider an outcome to be either an “event” or a “non-event.” In the context of our previous examples, counting the number of heads in a sequence of flips will be synonymous with counting the number of “events” that we have observed. There are three assumptions of the binomial distribution: There is fixed number of trials, \\(n\\), each of which has two possible outcomes Each trial is independent of the others Each trial has the same probability \\(p\\) of an event occurring We will let \\(X\\) describe an experiment which follows a binomial distribution with parameters for the number of trials (\\(n\\)), with probability of an event \\(p\\). Syntactically, we write this as \\(X \\sim Bin(n, p)\\). The probability distribution function is described by the following formula: \\[P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}\\] and the possible observed values of \\(X\\) are \\(x = 0, 1, ..., n\\). Our coin flipping example above is a case of a random experiment following a binomial distribution, with distribution parameters \\(n = 3\\) and \\(p = 0.5\\). Substituting these values into our distribution function, we may describe the random experiment with the formula: \\[P(X = x) = \\binom{3}{x} (0.5)^x (1-0.5)^{3-x}\\] Perhaps new to us here is the leading term in the expression above, \\(\\binom{n}{x}\\), which is called a binomial coefficient, and can be written with the formuila \\[ \\binom{n}{x} = \\frac{n!}{x!(n-x)!} \\] where \\(n! = n \\times (n-1) \\times (n-2) \\times \\ ... \\ \\times 2 \\times 1\\) (known as a factorial). In words, we might say \\(\\binom{n}{x}\\) as “n choose x.” While this may seem daunting at first, the need for it is quite reasonable. Consider our current experiment, with \\(n = 3\\), and the list of the possible outcomes, given above: \\[\\mathcal{S} = \\{HHH, HHT, HTH, THH, TTH, THT, HTT, TTT\\}.\\] When we are investigating the probability of observing two heads after flipping a coin three times, we are asking: “with \\(n = 3\\) flips, how many ways can we choose \\(x = 2\\) heads,” or, “three choose two.” Counting the number of scenarios above in which two heads appear tells us that it is three, and indeed, we find that \\[ \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\cdot(1 \\times 1)} = \\frac62 = 3 \\] Using the binomial distribution function for \\(n = 3\\) and \\(p = 0.5\\), confirm the values here that we given in the table above tmpTab &lt;- cbind.data.frame(x = 0:3, &#39;P(X=x)&#39; = c(&#39;1/8&#39;, &#39;3/8&#39;, &#39;3/8&#39;, &#39;1/8&#39;)) kable(tmpTab, align = &#39;c&#39;) x P(X=x) 0 1/8 1 3/8 2 3/8 3 1/8 The mean of a binomial distribution in \\(E(X) = np\\) and the variances is \\(Var(X) = np(1-p)\\) 2.2.1 Plot of Binomial We can visualize a binomial distribution with a plot: each of the values on the \\(x\\)-axis represent a number of events observed, while the values on the \\(y\\)-axis represent the probabilities x &lt;- 0:3 y &lt;- dbinom(x, 3, 0.5) barplot(y, names.arg = x, xlab = &#39;Number of Heads Observed on Three Flips&#39;, ylab = &#39;Probability&#39;, yaxt=&#39;n&#39;) axis(side = 2, at = seq(0, 0.45, by = 0.05), pos = c(0, 0), labels = seq(0, 0.45, by = 0.05)) Of course, as the number of flips \\(n\\) changes, so does the associated plot x &lt;- 0:6 y &lt;- dbinom(x, max(x), 0.5) barplot(y, names.arg = x, xlab = &#39;Number of Heads Observed on Six Flips&#39;, ylab = &#39;Probability&#39;) 2.3 Normal Distribution The normal distribution, also known as a Gaussian distribution, is a continuous distribution, and is perhaps the most well recognized of the statistical distributions, often informally referred to as a “bell curve.” curve(dnorm(x), from = -3, to = 3, main = &#39;maybe delete this since we do plots below&#39;) There are a number of properties that together characterize the normal distribution: There are two parameters for the normal distribution, the mean \\(\\mu\\) (pronounced “myu”) and the variance \\(\\sigma^2\\) (“sigma squared”) \\(\\mu\\) is the mean, or expected value, and represents the most probably value of the distribution. That is, observations from a normal distribution are more likely to be close to \\(\\mu\\) than away from it Observations are equally likely to be the same magnitude above \\(\\mu\\) as they are below it. In other words, the distribution is centered around \\(\\mu\\). We see this concept expressed in every day language when we offer estimates of some value: “The cost is ‘x,’ plus or minus ‘y’” The second parameter, \\(\\sigma^2\\), describes how concentrated values are around the mean. The smaller the value of \\(\\sigma^2\\), the more observations that will be close to \\(\\mu\\). Likewise, larger values of \\(\\sigma^2\\) result in higher dispersion, or more values further away from \\(\\mu\\). If a random variable \\(X\\) follows a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we may express it syntactically with \\(X \\sim N(\\mu, \\sigma^2)\\). A special case of this known as the standard normal distribution arises when \\(\\mu = 0\\) and \\(\\sigma^2 = 1\\). We usually write this with the letter \\(Z\\), or \\(Z \\sim N(0, 1)\\). Many things with which we are familiar can be described with a normal distribution, including the height of individuals in a population, grades on an exam, and average shoe size. Amazingly, as we will see in the following chapters, even the number of events that we observe from a binomial distribution will follow as normal distribution, as the binomial parameter \\(n\\) increases towards infinity. In addition to most things that we measure following a normal distribution, we will also see that the errors we make when measuring are often normal. When measuring the arc distance between two stars in the sky, astronomers are just as likely to record a measurement that is just over the true value as they are to record one that is just under it as well. [Maybe need to describe difference between pdf and pmf since we don’t use P(X = x)] \\[ p(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\ e^{- \\frac{(x-\\mu)^2}{2\\sigma^2}} \\] The mean of a normal distribution is \\(E(X) = \\mu\\) and the variance is \\(Var(X) = \\sigma^2\\) 2.3.1 Plot for Normal In constrast to the binomial distribution, which had discrete probabilities, the normal distribution is continuous, requiring that probabilities be calculated via integration (this is somewhat analagous to the trapazoidal rule, for those who remember from calculus). As a consequence of this, we are not able to ask meaningful questions about the probability of a specific point (the intergral of a point is always zero, maybe getting into weeds here). We won’t go into detail here, mostly because I’m not quite sure what details we might need, but supposing that \\(Z \\sim N(0, 1)\\), we might ask, what is the probability that \\(Z\\) is greater than 1? This probability is represented by the red region in the plot below x &lt;- seq(-3, 3, 0.01) y &lt;- dnorm(x) plot(x, y, type = &#39;l&#39;) polygon(c(x[x &gt; 1], max(x), 1), c(y[x &gt; 1], 0, 0), col = &#39;red&#39;) Things in normal that I didn’t include but we may want calculating the probabilities more detail on how/where/when it comes up we haven’t introduced estimators yet, so somewhat limited 2.4 Poisson Distribution The Poisson distribution, like the binomial, is a discrete distribution, in that it concerns itself with count data. Specifically, a Poisson distribution describes the number of independent events that may occur within a fixed interval of time. For example, we may be interested in the number of cars that pass through a busy intersection from noon to 1pm every day, or the number of major floods that occur in an area every 100 years. Perhaps the most famous example of the Poisson distribution comes courtesy of Ladislaus Bortkiewicz, a Russian statistician who, in 1898, showed that the number of Prussian soldiers killed by being kicked by a horse in a twenty year period followed a Poisson distribution (also child suicides, but that’s less fun). The Poisson distribution has a single parameter, \\(\\lambda\\), which describes the rate at which events occur, and a random variable following a Poisson distribution may be expressed as \\(X \\sim Pois(\\lambda)\\) (People who write \\(X \\sim Po(\\lambda)\\) are heathens). A random variable following a Poisson distribution has the following assumptions: The value of \\(X\\), being a count, can be any non-negative integer, i.e., \\(0, 1, 2, \\dots\\) The occurence of one event in a time interval is independent of another event. One soldier being kicked by a horse has no impact on the probability of another solider being kicked by a horse. \\(\\lambda\\), which may be any number greater than \\(0\\), describes the rate at which events occur [and is independent of the occurence of events] [Two events cannot occur at the exact same time, though they probably don’t need this] The distribution function of a Poisson random variable with rate \\(\\lambda\\) can be expressed \\[ P(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\] One surprisingly detail about the Poisson distribution is the relationship between the mean and the variance. For both, we have that \\(E(X) = Var(X) = \\lambda\\). 2.4.1 Plots for Poisson As we look at the plot for the Poisson, we will notice one aspect in particular that distinguishes it from the plots of both the binomial and normal distributions: it is no longer symmetric. This is a consequence of the range of values that a Poisson random variable can take on. Whereas a binomial random variable was bounded between \\(0\\) and \\(n\\), the number of trials conducted, and where the normal distribution allowed any real number, the Poisson is bounded below by \\(0\\), while having no theoretical upper bound. Given below is a plot of the distribution with \\(\\lambda = 4\\) (it’s obvious here that choosing a specific value is inadequate. We can replace these plots with distribution exploration apps) x &lt;- 0:15 y &lt;- dpois(x, lambda = 4) barplot(y, names.arg = x, xlab = &#39;Number of Events Observed in Interval&#39;, ylab = &#39;Probability&#39;, main = expression(paste(&quot;Poisson distribution with &quot;, lambda, &quot; = 4&quot;))) Need to do maybe: relate \\(\\lambda\\) to a specific interval, say, an hour Interactive (in general not just poisson) 2.5 t Distribution Actually not sure on this here, as we haven’t introduced estimators. Will come back to this 2.5.1 Plot for t distribution 2.6 Review of Distributions [[table]] "],
["ch6.html", "3 Sampling Distributions and the Central Limit Theorem 3.1 Introduction 3.2 Sampling Distributions 3.3 Central Limit Theorem", " 3 Sampling Distributions and the Central Limit Theorem “While nothing is more uncertain than a single life, nothing is more certain than the average duration of a thousand lives.” - Elizur Wright “Everything that can be counted does not necessarily count; everything that counts cannot necessarily be counted.” - Albert Einstein Learning objectives Learn to differentiate between statistics and parameters Understand the concept of sampling distributions Conceptual understanding of Central Limit Theorem and how it applies to sample means 3.1 Introduction Suppose policy makers and public health experts in Iowa are concerned with Iowan’s fast food intake. To understand this further, the officials want to determine the average monthly spending on fast food for all Iowans. However, it would be very expensive and costly to have all 3.2 million Iowans track and report their total monthly spending on fast food. And certainly many Iowans would not be willing to share personal financial details with public health researchers or government officials. This means it is impossible for the officials to know the true mean amount of money that Iowans spend on fast food each month. The true numeric quantity about the population, such as this, is known as a population parameter. While we will never ever know the truth, there are still options. The officials can take a sample of Iowans and have those that consent to share their information report their monthly spending on fast food. Then, they can take the sample mean, which gives them an estimate of the average monthly spending on fast food. The sample mean is an example of a sample statistic, which is a numerical quantity about the sample. In other words, statistics are what investigators know, and parameters are what investigators want to know. The statistical framework (pictured below) allows us to make inference about population parameters using sample statistics. This means the researchers can use a random sample of Iowans’ monthly fast food spending to make generalizations about the average monthly spending for all Iowans. The numerical quantities of interest can be many different things - means, proportions, standard deviations, etc.. In the fast food example, the parameter of interest was a population mean and the sample statistic was the sample mean. In this chapter, we will specifically focusing on estimating means. Figure 3.1: Statistical Framework The statistical framework outlines the process of making inference using sample statistics to estimate population parameters. Later chapters in this textbook will cover the mathematical details of this process. In trying to make proper inference, we also want to ensure our estimated statistic is measuring the parameter well. To that end, there are two major statistical issues we concern ourselves with: On average, does our estimate tend to be centered around the true answer, or is it biased? How much variability is there likely to be in our sample? The difference between our estimate and our parameter is called bias. Variance describes the spread of our data, and is sometimes called noise. Sometimes we talk about spread in terms of precision, which is the inverse of variance. The more precision we have, the less variance, and vice versa. A good statistic will have little or no bias and would have minimal variability. We can visualize both bias and variability using a dart board analogy. Figure 3.2: Bias and Variability Illustration On the upper left target, the darts are hitting the bullseye with low bias and low variability, shown by the darts having minimal spread and all hitting the bullseye. This is the most desirable outcome when the goal is to hit the bullseye. In the upper right target, we see a lot more variability, as the darts are no longer highly concentrated on the bullseye. However, the dart locations are still centered around the bullseye, and this is why we consider this target to have low bias. This situation is less ideal than having low bias and low variance, but is stil preferable to targets in the bottom row, where we have high bias. In the bottom left target, we have high bias and low variability, evidence by the high concentration of darts that are not hitting the bullseye. The consistency is why we saw there is low variability, but if our goal is to hit the bullseye, we are not going to acheive that goal. Finally, the bottom right target is the worst possible outcome - high bias and high variability. We are not hitting the bullseye and the darts are landing erratically. Statisticians work hard to develop inferential procedures that allow us to estimate population parameters with little to no bias and low variability. Definitions Population Parameter: The true numeric quantity about a population Sample Statistic: A numerical quantity about the sample Inference: The process of making generalizations about the population Bias: The difference between our estimate and our parameter Variability: The spread or error in the data Precision: Inverse of variance, how 3.2 Sampling Distributions In order to make inference, we must be able to quantify our uncertainty about the population parameter based on our sample data. To quantify our uncertainty, we must first establish where it comes from - the sampling process. Any time we take a sample from the population, we will get a different sample mean \\(\\overline{x}\\). In other words, \\(\\overline{x}\\) is a numeric quantity which assumes a value based on the outcome of a random experiment - the process of drawing a sample at random from the population. This should sound familiar - this is the definition of a random variable! We can use this logic for any statistic of interest. As we’ve described in the past, random variables have probability distributions. When the random variable is a statistic, this probability distribution is called the sampling distribution. Sampling distributions reflect which values of the statistic are likely and which values are improbable. As we will see later in this chapter, this uncertainty depends on how many individuals we sample and how variable the data we measure is. Exercises The applet below is designed to help you get familiar with the concept of random sampling. The plot on the left side gives the population distribution. Each subject in the population is represented by one box, and the population consist of 26 people. The x-axis represents the value of the outcome variable for each individual, and when multiple people have the same value, their boxes are stacked on top of each other. For example, we have one subject in the population with a value of 0, three subjects with values of 1, and so on. The plot on the right displays the values for the subjects in our sample, and these subjects are indicated by green coloring in both the population and sample distributions. We can take samples from our population of various sizes by changing the value of the slider at the top and clicking on the “Sample” button. Set the sample size to 2 and click the “Sample” button five times. Fill out the following table with the sample means observed in your five samples. Sample Number Sample mean 1 2 3 4 5 Did you get the same sample mean for any of your five samples? Was the sample mean ever equal to the population mean in any of your five samples? If not, how close were your sample means to the true population mean? Now set the sample size to 15 and click the “Sample” button five times. Fill out the following table with the sample means observed in your five samples. Sample Number Sample mean 1 2 3 4 5 Did any of your five simulations give you a sample mean equal to the population mean? Was the sample mean ever equal to the population mean in any of your five samples? If not, how close were your sample means to the true population mean? Compare your results from problem 1 and problem 2. In either case were you able to obtain a sample mean equal to the population mean? Which one had sample means with more variability? What does this indicate about the relationship between the sample size and the distribution of sample means in the context of repeated sampling? As we’ve seen earlier in this book, we will use upper-case letters to denote random variables, and lower-case letters to denote possible values they can take on. When it comes to the sampling distribution of the mean, \\(\\overline{X}\\) is the random variable, which arises from repeated random sampling from the population and then taking a sample mean, and \\(\\overline{x}\\) is an observed sample mean we might see. In describing a sampling distribution, we are often interested in the mean and standard deviation - this gives information about typical values the statistic might take on as well as how spread out the distribution is. We refer to the mean of a statistic as the expected value and the standard deviation as the standard error. For the random variable describing the sample mean, these are denoted as \\(E(\\overline{X})\\) and \\(SE(\\overline{X}) = \\sqrt{Var(\\overline{X})}\\), respectively. Let’s return to the fast food scenario to motivate our development, but for now let’s assume there are only five individuals in the entire population. The monthly spending for those five individuals (rounded to the nearest dollar) is as follows: Person Monthly Spending A 8 B 22 C 22 D 36 E 50 The population mean can be found by taking the average monthly spending of these five individuals, as they are the only people in this population. This means the population mean is 27.6. Now suppose we are taking samples of three individuals from this population. There are \\(\\binom{5}{3}\\) = 10 ways we can sample three people from this population. Since this is a small population, we can enumerate all possible samples, the values we would obtain for the monthly spending in each sample, and then the sample mean monthly fast food spending for each sample: Sample Values \\(\\overline{x}\\) (A, B, C) (8, 22, 22) 17.33 (A, B, D), (A, C, D) (8, 22, 36), (8, 22, 36) 22.00 (A, B, E), (A, C, E), (B, C, D) (8, 22, 50), (8, 22, 50), (22, 22, 36) 22.00 (A, D, E), (B, C, E) (8, 36, 50), (22, 22, 50) 26.67 (B, D, E), (C, D, E) (22, 36, 50), (22, 36, 50) 36.00 One thing to note is that none of the sample means are actually equal to the population mean. This is often the case! Based on this table, we can construct the sampling distribution of \\(\\overline{X}\\) for a sample of size three. Why is our sample mean often not equal to the population mean? Probability P(\\(\\overline{x}\\) = 17.33) 0.1 P(\\(\\overline{x}\\) = 22) 0.2 P(\\(\\overline{x}\\) = 26.67) 0.3 P(\\(\\overline{x}\\) = 31.33) 0.2 P(\\(\\overline{x}\\) = 36) 0.2 With this probability distribution, we can get the expected value of the sampling distribution. Whenever we think about probability, we are thinking about long-run frequencies, so when we think about the expected value, we are thinking about the average sample mean if we were to take repeated samples of size three from this population. The probability distribution indicates that if we took samples of size three from this population over and over again (say 1,000 times), we would end up with 10% with a mean of 17.33, 20% with a mean of 22, 30% with a mean of 26.67; and so on. So the expected value (average) we would observed if we kept taking samples over and over would be: (0.1 \\(\\times\\) 17.33) + (0.2 \\(\\times\\) 22) + (0.3 \\(\\times\\) 26.67) + (0.2 \\(\\times\\) 31.33) + (0.2 \\(\\times\\) 36) = 27.6 But wait! That is the population mean. This illustrates an extremely powerful property of the sample mean - the expected value of the sample mean (\\(\\overline{X}\\)) is equal to the population parameter (\\(\\mu\\))! Because of this, we say that the sample mean is an unbiased estimator of the population mean. While we illustrated the property with a small example, this holds regardless of the population or sample size. Definitions Expected Value: The mean of a statistic in repeated sampling Standard Error: The standard deviation of a statistic (including the mean) in repeated sampling Unbiased Estimator: The statistic with an expected value equal to the true population parameter 3.3 Central Limit Theorem In the last section, we used a toy example to conceptualize repeated sampling and the property of the sample mean being an unbiased estimator. Now we will formalize these properties. For any population distribution which can be described by a random variable \\(X\\) with mean \\(\\mu\\) and variance \\(\\sigma^2\\), the sample distribution of the mean based on sample of size \\(n\\) (\\(\\overline{X}_n\\)) has the following properties: The expected value of the sampling distribution is \\(\\mu\\) \\[E(\\overline{X}_n) = \\mu\\] The variance of the sampling distribution is \\[Var(\\overline{X}_n) = \\frac{\\sigma^2}{n}\\] Using these formulas we are able to describe the typical value of the sample mean and how variable the sample mean is in repeated sampling. Notice that the expected value does not depend on the sample size, \\(n\\), but the variance does. This means regardless of the sample size, the sample mean is an unbiased estimator of the population mean. But, as the sample size increases, the variance decreases, and we get a more precise estimate of the population mean. As we’ve seen in the past, it is more common to talk about the standard deviation than the variance and the standard deviation is the square root of the variance. The quantity \\(\\sqrt{Var(\\overline{X}_n)} = \\sigma / n\\) is primarily called the standard error of the mean, and is denoted by \\(SE(\\overline{X}_n)\\). We use the term standard error to make it really clear that it is referencing the sampling distribution of the mean, but all standard errors could be referred to as standard deviations. Conversely, not all standard deviations could be referred to as a standard error - the term is only used in describing the distribution of the sample mean. In addition to knowing the mean and standard error of the sample mean, we can also describe the distribution of sample means in repeated sampling. As we discussed in the last chapter on probability distributions, a distribution for the sample mean provides us with a way to quantify which sample mean values are likely and which values are unlikely. As it turns out, when we repeatedly sample from a population, and continue to calculate the sample mean from each sample, the distribution of the sample means will be normally distributed. This brings us what is largely considered the “fundamental theorem of statistics” Central Limit Theorem If the sample size is “large,” the sampling distribution of \\(\\overline{X}\\) is approximately normal, regardless of the characteristics of the underlying population. \\[\\overline{X}_n \\sim N(\\mu, \\sigma^2/n)\\] Generally, we consider a sample to be “large” enough if the sample size, \\(n \\geq 30\\). Because the variance of \\(\\overline{X}\\) is inversely related to the sample size, as the \\(n\\) increases, the variance decreases and the distribution becomes more concentrated. This is one of the most important, remarkable, and powerful results in all of statistics. In the real world, we rarely know the underlying population distribution of our data, however, the Central Limit Theorem (CLT) says: we don’t have to! Exercises The applet below is designed to help your conceptual understanding of the CLT. You can change the underlying population distribution, the size of the samples taken (\\(n\\)), and the number of experiments performed. Each experiment consists of taking a sample of the specified size from the population and calculating the sample mean. The top left panel (blue) shows the underlying population distribution. The top right panel (red) shows the data from the most recent sample, with the sample mean from that specific sample indicated by the dashed black line. The bottom panel (gold) shows us the distribution of sample means from all the experiments, with the observed mean of the sample means indicated by the dashed black line and the true underlying population mean indicated by the solid blue line. Once you select the parameters to the values you want, click “Run Simulation” to tabulate the results. Set the population distribution to Normal, the sample size to 30, and perform 100 experiments to collect 100 sample means. Describe the histogram of the the data from the last experiment. Comment on the modality and skew. Describe the histogram of the distribution of sample means from all experiments. What is the range of values observed for the distribution of sample means? How does this compare the the range of values observed in the data from the last experiment? Now adjust the sample size to 100. Perform 100 experiments. What is the range of values observed for the distribution of sample means? How does this compare to the range observed when the sample size was 30? What about the range of values observed in the data from the last experiment - did this change much when the sample size was increased? Play around with various sample sizes. How does changing the sample size effect the spread of the distribution of sample means? Return to a sample size of 30, but change the population distribution to be right skewed. Perform 1,000 experiments. Describe the histogram of the the data from the last experiment. Comment on the modality and skew. Describe the histogram of the distribution of sample means from all experiments. Does it resemble the population distribution? Re-run the simulation using a sample size of 10. How does this effect the distribution of the sample means? How does this compare to what you observed when taking samples of size 10 with a normal population distribution? Change the population distribution to be left skewed, set the sample size to 80, and perform 1,000 experiments. Describe the histogram of the the data from the last experiment. Comment on the modality and skew. Describe the histogram of the distribution of sample means from all experiments. Does it resemble the population distribution? Run the simulation with these parameters a few times and pay attention to how the mean of the distribution of sample means compares to the population mean. Is the population mean similar or different from the mean of the sample means? What property does this illustrate? Change the parameters of the simulations as needed to answer the following true/false questions. Explain your answers. CLT tells us that the distribution of data from any experiment will be normally distributed. With a larger sample size, the data from the last experiment will resemble the population distribution. Performing 10 experiments is enough to see the effect of CLT. Regardless of the underlying population distribution and the sample size, the distribution of the sample means will be normally distributed. Increasing the sample size causes the data from a single experiment to look more and more normally distributed. "]
]
